/*
 * This Scala source file was generated by the Gradle 'init' task.
 */
package com.tfedorov.icebergdemo

import org.apache.spark.sql.{DataFrame, SparkSession}

object InitAndLoadDataAPP {

  val WAREHOUSE_DIR_PATH: String = "src/main/resources/output_iceberg"
//  val SPARK_CATALOG_PATH: String = WAREHOUSE_DIR_PATH + "spark_catalog/"
  val HARRY_CATALOG_PATH: String = WAREHOUSE_DIR_PATH + "/catalog/harry_ns/"

  def main(args: Array[String]): Unit = {
    println("Start" + this.getClass.getName)
    runHarry()
    println("End" + this.getClass.getName)
  }

  def runHarry(): Unit = {

    val spark: SparkSession = SparkSession
      .builder()
      .master("local[*]")
      .config("spark.driver.host", "localhost")
      //      .config("spark.driver.host", "localhost[*]")
      .config("spark.sql.extensions", "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions")
      //      .config("spark.sql.catalog.spark_catalog", "org.apache.iceberg.spark.SparkSessionCatalog")
      //      .config("spark.sql.catalog.spark_catalog.type", "hadoop")
      //      .config("spark.sql.catalog.spark_catalog.warehouse", SPARK_CATALOG_PATH)
      .config("spark.sql.catalog.harry_ns", "org.apache.iceberg.spark.SparkCatalog")
      .config("spark.sql.catalog.harry_ns.type", "hadoop")
      .config("spark.sql.catalog.harry_ns.warehouse", HARRY_CATALOG_PATH)
      .config("spark.sql.warehouse.dir", WAREHOUSE_DIR_PATH)
      // Iceberg configs
      .getOrCreate()

    val inputDF: DataFrame = spark.read
      .option("delimiter", ";")
      .option("inferSchema", "true")
      .option("header", "true")
      .csv("src/main/resources/input_data/Characters.csv")

    inputDF.printSchema()
    inputDF.show
    inputDF.createGlobalTempView("input_data")

//    spark.sql("""CREATE NAMESPACE IF NOT EXISTS harry_ns""")
    spark.sql(
      """
     CREATE TABLE IF NOT EXISTS harry_ns.input_table (Id  string,
          Name  string,
          Gender  string,
          Job  string,
          House  string,
          Wand  string,
          Patronus  string,
          Species  string,
          Blood_status  string,
          Hair_colour  string,
          Eye_colour  string,
          Loyalty  string,
          Skills  string,
          Birth  string,
          Death  string
          )
        USING iceberg PARTITIONED BY (Gender)"""
    )
    spark.sql("SELECT * FROM global_temp.input_data").show

    //    inputDF.writeTo("harry_ns.input_table").append()
    spark
      .sql(
        """
     INSERT INTO harry_ns.input_table
        SELECT Id,Name,Gender,Job,House,Wand,Patronus,Species,Blood_status,Hair_colour,Eye_colour,Loyalty,Skills,Birth,Death FROM global_temp.input_data
      """
      )
    spark.sql("SELECT * FROM harry_ns.input_table").show
  }
}
